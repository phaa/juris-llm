# Juris-LLM: Sistema de Perguntas e Respostas JurÃ­dico com RAG

Projeto de IA generativa com foco em **documentos jurÃ­dicos**, como a ConstituiÃ§Ã£o Federal de 1988, utilizando uma arquitetura RAG (Retrieval-Augmented Generation), LLM local ou na nuvem, observabilidade com Prometheus e Grafana, alÃ©m de MLOps com CI/CD, DVC e MLflow.

## ğŸš€ Funcionalidades

- âœ… **IngestÃ£o e chunking** inteligente de PDFs jurÃ­dicos  
- âœ… **VetorizaÃ§Ã£o semÃ¢ntica** com SentenceTransformers  
- âœ… **Armazenamento vetorial** com ChromaDB  
- âœ… **Busca semÃ¢ntica** e recuperaÃ§Ã£o com LangChain  
- âœ… **GeraÃ§Ã£o de respostas** com modelo LLaMA local (vLLM) ou Gemini (Vertex AI)  
- âœ… **API RESTful** com FastAPI  
- âœ… **Testes automatizados** com Pytest e TestClient  
- âœ… **Monitoramento** com Prometheus e Grafana  
- âœ… **CI/CD** com GitHub Actions e Google Cloud Run  
- âœ… **MLOps** com DVC + MLflow (em progresso)  

## ğŸ› ï¸ Tecnologias e Ferramentas

| Categoria             | Tecnologias                                                       |
|-----------------------|--------------------------------------------------------------------|
| ğŸ” VetorizaÃ§Ã£o         | `sentence-transformers`, `ChromaDB`, `LangChain`                  |
| ğŸ§  LLMs                | `vLLM` + `Hugging Face` + `Transformers` ou `Vertex AI` (Gemini)  |
| ğŸ§° Backend API         | `FastAPI`, `Pydantic`, `Uvicorn`                                  |
| ğŸ“¦ ContainerizaÃ§Ã£o     | `Docker`, `Docker Compose`, `NVIDIA CUDA Base Image`              |
| ğŸ”¬ Testes              | `Pytest`, `TestClient`, mocks                                     |
| ğŸ“Š Observabilidade     | `prometheus_client`, `Prometheus`, `Grafana`                      |
| ğŸ” CI/CD               | `GitHub Actions`, `Cloud Run`, `Artifact Registry`, `GCP`         |
| ğŸ§ª MLOps               | `DVC`, `MLflow` (em breve)                                        |

## ğŸ“‚ Estrutura de Pastas

```
juris-llm/
â”‚
â”œâ”€â”€ app/                      # CÃ³digo principal da aplicaÃ§Ã£o FastAPI
â”‚   â”œâ”€â”€ main.py               # Ponto de entrada da API
â”‚   â”œâ”€â”€ rag.py                # LÃ³gica do RAG (query + geraÃ§Ã£o)
â”‚   â”œâ”€â”€ chroma_loader.py      # Carregamento da coleÃ§Ã£o vetorial
â”‚   â”œâ”€â”€ models.py             # Modelos Pydantic (Entrada/SaÃ­da)
â”‚
â”œâ”€â”€ data/                     # Dados PDF / processados
â”‚
â”œâ”€â”€ scripts/                  # Scripts para chunking e vetorizaÃ§Ã£o
â”‚   â””â”€â”€ ingest.py
â”‚
â”œâ”€â”€ infra/                    # Infraestrutura (Docker, Prometheus, etc.)
â”‚   â”œâ”€â”€ Dockerfile.api
â”‚   â”œâ”€â”€ prometheus.yml
â”‚
â”œâ”€â”€ tests/                    # Testes automatizados
â”‚
â”œâ”€â”€ .github/workflows/        # CI/CD com GitHub Actions
â”‚
â”œâ”€â”€ .env                      # VariÃ¡veis de ambiente
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

## ğŸ“¦ InstalaÃ§Ã£o Local (com Docker)

```bash
# Clone o repositÃ³rio
git clone https://github.com/seu-usuario/juris-llm.git
cd juris-llm

# Crie seu arquivo .env
cp .env.example .env

# Suba os serviÃ§os
docker-compose up --build
```

## ğŸ§ª Testes

```bash
# No terminal (com ambiente ativado)
pytest
```

## ğŸ“ˆ Monitoramento

- Acesse o Prometheus em `http://localhost:9090`
- Acesse o Grafana em `http://localhost:3000`
  - User: `admin`
  - Pass: `admin`
  - Adicione Prometheus como data source e crie dashboards

## â˜ï¸ Deploy com CI/CD (Cloud Run)

Pipeline de CI/CD integrado com GitHub Actions:

- Autentica com chave de service account
- Faz build da imagem Docker
- Faz push para o Google Artifact Registry
- Faz deploy na Cloud Run com variÃ¡veis definidas

## ğŸ¤– Uso de LLMs

### Modelo Local

- Usando vLLM com suporte a CUDA
- Serve um endpoint HTTP separado da API

### Modelo via Vertex AI

- Gemini (preview): `gemini-2.5-flash-preview-05-20`
- IntegraÃ§Ã£o via SDK: `google-genai`

## ğŸ“š Futuras ExtensÃµes

- Interface Web com Streamlit ou Next.js
- Armazenamento em banco de dados (ex: PostgreSQL + pgvector)
- Cache com Redis
- AutenticaÃ§Ã£o com OAuth2
- Fine-tuning de LLM

## ğŸ‘¨â€ğŸ’» Autor

Pedro Henrique Azevedo  
[LinkedIn](https://www.linkedin.com/in/pedro-henrique-azevedo/) â€¢ [GitHub](https://github.com/phazevedo)

## ğŸ“ LicenÃ§a

Este projeto estÃ¡ licenciado sob os termos da **MIT License**.